#+TITLE:       分布式问题 
#+AUTHOR:      congleetea
#+EMAIL:       congleetea@m6
#+DATE:        2017-04-12 Wed
#+URI:         /blog/%y/%m/%d/分布式问题
#+KEYWORDS:    internet,distributed
#+TAGS:        lines,internet
#+LANGUAGE:    en
#+OPTIONS:     H:3 num:nil toc:nil \n:nil ::t |:t ^:nil -:nil f:t *:t <:t
#+DESCRIPTION: 关于分布式

* 为什么需要分布式
引用https://www.zhihu.com/question/23645117/answer/129505434 的回答：

先想想为什么会有分布式，分布式怎么来的。传统的电信、银行业，当业务量大了之后，普通服务器CPU/IO/网络到了100%，
请求太慢怎么办？最直接的做法，升级硬件，反正也不缺钱，IBM小型机，大型机，采购了堆硬件。但是互联网不能这么干，
互联网没有那么财大气粗，还有很多初创，能不能赚钱还不知道。所以就有了软件方面的解决方案：分布式系统，简单说，
就是一台服务器不行，我用两台、10台、100台...这就要软件系统需要支持。  那么软件设计者就需要考虑了，那么多台机
器，我如何 *让他们协同工作，这就需要一个调度中心（或注册中心）* ；肯定涉及到机器间通信，那么需要一个高效的RPC框架；
一个请求过来了，如何分发， *需要一个请求分发系统（负载均衡）* ；然后还要考虑每个角色都不能成为性能瓶颈；还有要能
方便的进行横向扩展，还有考虑单节点故障。  这些事你在设计分布式系统需要考虑的问题。笔者现在在互联网行业，说的
都是互联网业的方案。比如现在负载均衡用nginx/HA，前者更轻量，后者负载均衡算法更丰富；RPC框架用dubbo（可用当当
的dubbox）；用zookeeper中注册中心，所有服务注册在这里。 需要分布式系统，并发量肯定不低，那么有了上面的还是
不够的，还需要考虑cache、mq、job、db等方面的问题。cache，现在第三方缓存也比较成熟，redis/memcache等；mq，
rabbitmq,kafka等等也不错；job，现在第三方任务框架有elasticjob和tbschedule，或者你用quartz也支持分布式环境下
的任务，不过quartz就没有运维工具了。DB，数据库最好在项目前期就考虑好业务拆分，系统拆分后DB对应的垂直拆分，
后期可做读写分离，一主多从，甚至多主多从，业界也有了相应的解决方案。


* 分布式算法

** 一致性哈希算法（consistent hashing）
[[http://blog.csdn.net/cywosp/article/details/23397179][五分钟理解一致性哈希算法(consistent hashing)]]

需要明白一下几点：

- 判定哈希算法好坏的四个定义
平衡性（Balance），单调性（Monotonicity），分散性（Spread），负载（Load）

- 环形哈希空间
需要注意的是，环形哈希空间是一个空间，需要把适当的对象映射到这个环形空间上，需要映射的对象有两部分：一个是数据,
另一个是服务器集群的所有节点。也就是一个数据根据哈希算法（通常是使用数据提供的key计算）确定该数据在哈希环上的位
置，一个服务器节点也根据哈希算法（通常是使用节点的IP和别名）确定该服务器在哈希环上的位置。数据的走向是朝顺时针
方向去往最近的节点上。

- 节点增减时的数据迁移与单调性
当节点出现增加的时候，只需要把该节点逆时针方向的这些数据迁移到新节点上就行，其他数据不需要动；如果删除节点时，只
需要把该节点的数据前往顺时针方向最近的节点即可，其他数据也不需要动。这样能满足一致性的要求。

- 虚拟节点与平衡性
如果节点很少的话，有可能节点的分布很不均匀，这样节点承载的压力也就很不均衡了，于是引入了虚拟节点。虚拟节点其实就是
同一个节点去映射多个哈希点。比如IP=192.168.1.100的一个节点，如果使用两个虚拟节点，那么使用哈希算法：

#+BEGIN_SRC text
Hash("192.168.1.100#1"); // NODE1-1
Hash("192.168.1.100#2"); // NODE1-2
#+END_SRC

就可以让同一个节点接受不同范围的数据，有利于数据的均衡。但是需要多少个虚拟节点呢？一般推荐每个实际节点推荐使用150个虚拟
节点，这样做还有一个好处就是，增减机器的时候只需要迁移非常少的数据。


